{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<!-- ![logog](https://raw.githubusercontent.com/Pacific-AI-Corp/langtest/refs/heads/main/docs/assets/images/logo.png) -->\n",
        "![logog](https://raw.githubusercontent.com/Pacific-AI-Corp/langtest/main/docs/assets/images/logo.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Pacific-AI-Corp/langtest/blob/main/demo/tutorials/benchmarks/Langtest_Cli_Eval_Command.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**LangTest**is an open-source python library designed to help developers deliver safe and effective Natural Language Processing (NLP) models. Whether you are using **John Snow Labs, Hugging Face, Spacy**\n",
        "models or **OpenAI, Cohere, AI21, Hugging Face Inference API and Azure-OpenAI** based LLMs, it has got you covered. You can test any Named Entity Recognition (NER), Text Classification, fill-mask, Translation model using the library. We also support testing LLMS for Question-Answering, Summarization and text-generation tasks on benchmark datasets. The library supports 60+ out of the box tests. For a complete list of supported test categories, please refer to the [documentation](http://langtest.org/docs/pages/docs/test_categories)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This notebook provides a comprehensive overview of benchmarking Language Models (LLMs) in Question-Answering tasks. Explore step-by-step instructions on conducting robustness and accuracy tests to evaluate LLM performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Getting started with LangTest CLi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPPUwGvzyAoV",
        "outputId": "670c68e7-83fe-418c-8e3e-094590f5b7f2"
      },
      "outputs": [],
      "source": [
        "!pip install -q langtest[all]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Example JSON"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "{\n",
        "    \"task\": \"question-answering\",\n",
        "    \"model\": {\n",
        "        \"model\": \"google/flan-t5-base\",\n",
        "        \"hub\": \"huggingface\"\n",
        "    },\n",
        "    \"data\": [\n",
        "        {\n",
        "            \"data_source\": \"MedMCQA\"\n",
        "        },\n",
        "        {\n",
        "            \"data_source\": \"PubMedQA\"\n",
        "        },\n",
        "        {\n",
        "            \"data_source\": \"MMLU\"\n",
        "        },\n",
        "        {\n",
        "            \"data_source\": \"MedQA\"\n",
        "        }\n",
        "    ],\n",
        "    \"config\": {\n",
        "        \"model_parameters\": {\n",
        "            \"max_tokens\": 64\n",
        "        },\n",
        "        \"tests\": {\n",
        "            \"defaults\": {\n",
        "                \"min_pass_rate\": 1.0\n",
        "            },\n",
        "            \"robustness\": {\n",
        "                \"add_typo\": {\n",
        "                    \"min_pass_rate\": 0.70\n",
        "                }\n",
        "            },\n",
        "            \"accuracy\": {\n",
        "                \"llm_eval\": {\n",
        "                    \"min_score\": 0.60\n",
        "                }\n",
        "\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example Yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0ZVlGWBJyGO8"
      },
      "outputs": [],
      "source": [
        "yaml_content = \"\"\"\n",
        "task: question-answering\n",
        "model:\n",
        "  model: google/flan-t5-base\n",
        "  hub: huggingface\n",
        "data:\n",
        "- data_source: MedMCQA\n",
        "- data_source: PubMedQA\n",
        "- data_source: MMLU\n",
        "- data_source: MedQA\n",
        "config:\n",
        "  model_parameters:\n",
        "    max_tokens: 64\n",
        "    device: 0\n",
        "    task: text2text-generation\n",
        "  tests:\n",
        "    defaults:\n",
        "      min_pass_rate: 0.65\n",
        "    robustness:\n",
        "      add_typo:\n",
        "        min_pass_rate: 0.7\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The content stored in the variable `yaml_content` (which should be formatted in valid YAML syntax) is written to the opened file using the `f.write` method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "zPbGsd-Iydxv"
      },
      "outputs": [],
      "source": [
        "import yaml\n",
        "\n",
        "# write a yaml file\n",
        "with open('config.yml', 'w') as f:\n",
        "    f.write(yaml_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Langtest eval Command for model benchmarking\n",
        "\n",
        "The langtest command-line interface offers a powerful tool for evaluating language models on specific tests. This is achieved through the langtest eval command. Imagine you want to test a model named `google/flan-t5-base`, a large language model developed by Google. The `langtest eval` command allows you to do this. To use it, you'll provide additional information through arguments. The `-m google/flan-t5-base` argument specifies the model you want to evaluate.  The `-h huggingface` argument tells langtest that the model resides on Hugging Face, a popular platform for sharing pre-trained models. Finally, the `-c config.yml` argument points to a configuration file containing details about the evaluation process, such as the test itself and the metrics used to measure performance. In certain environments, like Jupyter notebooks, you might see an ! symbol preceding the entire command. This symbol is specific to those environments and allows you to run shell commands within them. By combining langtest eval with the appropriate arguments, you can streamline the process of evaluating your language model's capabilities on various language tests.\n",
        "\n",
        "Breakdown of the langtest eval command:\n",
        "\n",
        "* langtest eval: This core part of the command invokes the evaluation functionality within langtest.\n",
        "* -m <model_identifier>: This argument specifies the model you want to evaluate. In the example, `google/flan-t5-base` indicates the model comes from Google and is named flan-t5-base.\n",
        "* -h <hub>: This option defines where the model is hosted. Here, -h means hub, a popular repository for pre-trained models.\n",
        "* -c <config_file>: This argument specifies the configuration file that controls the evaluation process. This file typically holds settings like evaluation metrics and test parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3O9AFRlz2y5",
        "outputId": "7ce24c8e-d92f-4f52-98ef-a132bf9989c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-04-02 13:13:57.744792: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-02 13:13:57.744869: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-02 13:13:57.752894: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-04-02 13:13:58.895310: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "cannot import name 'LangtestRetrieverEvaluator' from 'langtest.evaluation' (/usr/local/lib/python3.10/dist-packages/langtest/evaluation/__init__.py) please install llama_index using `pip install llama-index`\n",
            "INFO:langtest.leaderboard:Initializing new langtest leaderboard...\n",
            "/root/.langtest/\n",
            "Test Configuration : \n",
            " {\n",
            " \"model_parameters\": {\n",
            "  \"max_tokens\": 64,\n",
            "  \"device\": 0,\n",
            "  \"task\": \"text2text-generation\"\n",
            " },\n",
            " \"tests\": {\n",
            "  \"defaults\": {\n",
            "   \"min_pass_rate\": 0.65\n",
            "  },\n",
            "  \"robustness\": {\n",
            "   \"add_typo\": {\n",
            "    \"min_pass_rate\": 0.7\n",
            "   }\n",
            "  }\n",
            " }\n",
            "}\n",
            "================================================================================\n",
            "                                    MedMCQA                                     \n",
            "================================================================================\n",
            "Generating testcases...: 100% 1/1 [00:00<00:00, 13797.05it/s]\n",
            "WARNING:root:[W009] Removing samples where no transformation has been applied:\n",
            "[W010] - Test 'add_typo': 156 samples removed out of 4183\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "================================================================================\n",
            "                                    PubMedQA                                    \n",
            "================================================================================\n",
            "Generating testcases...: 100% 1/1 [00:00<00:00, 20460.02it/s]\n",
            "WARNING:root:[W009] Removing samples where no transformation has been applied:\n",
            "[W010] - Test 'add_typo': 1 samples removed out of 1000\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "================================================================================\n",
            "                                      MMLU                                      \n",
            "================================================================================\n",
            "Generating testcases...: 100% 1/1 [00:00<00:00, 22429.43it/s]\n",
            "WARNING:root:[W009] Removing samples where no transformation has been applied:\n",
            "[W010] - Test 'add_typo': 35 samples removed out of 1089\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "================================================================================\n",
            "                                     MedQA                                      \n",
            "================================================================================\n",
            "Generating testcases...: 100% 1/1 [00:00<00:00, 19065.02it/s]\n",
            "WARNING:root:[W009] Removing samples where no transformation has been applied:\n",
            "[W010] - Test 'add_typo': 50 samples removed out of 1323\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "INFO:langtest.leaderboard:Testcases saved to /root/.langtest/testcases/question-answering&MedMCQA,PubMedQA,MMLU,MedQA&robustness.\n",
            "================================================================================\n",
            "                                    MedMCQA                                     \n",
            "================================================================================\n",
            "Running testcases... :   0% 5/4027 [00:01<11:06,  6.03it/s]/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1157: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "Running testcases... : 100% 4027/4027 [06:56<00:00,  9.67it/s]\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "================================================================================\n",
            "                                    PubMedQA                                    \n",
            "================================================================================\n",
            "Running testcases... : 100% 999/999 [01:50<00:00,  9.04it/s]\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "================================================================================\n",
            "                                      MMLU                                      \n",
            "================================================================================\n",
            "Running testcases... : 100% 1054/1054 [01:51<00:00,  9.46it/s]\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "================================================================================\n",
            "                                     MedQA                                      \n",
            "================================================================================\n",
            "Running testcases... : 100% 1273/1273 [02:14<00:00,  9.50it/s]\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "INFO:langtest.leaderboard:Updating leaderboard...\n",
            "\n",
            "\n",
            "================================================================================\n",
            "                                   robustness                                   \n",
            "================================================================================\n",
            "INFO:langtest.leaderboard:robustness Leaderboard\n",
            "|    | model               |   avg |     std |   MMLU |   MedMCQA |   MedQA |   PubMedQA |\n",
            "|---:|:--------------------|------:|--------:|-------:|----------:|--------:|-----------:|\n",
            "|  1 | google/flan-t5-base | 98.25 | 2.06155 |     97 |        96 |     100 |        100 |\n",
            "--------------------------------------------------------------------------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!langtest eval -m google/flan-t5-base -h huggingface -c config.yml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVm3XwHr-qNa",
        "outputId": "7ef92ed4-11d0-45e8-e1a2-0c8be708cb9f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-04-02 13:29:36.147363: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-02 13:29:36.147430: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-02 13:29:36.155959: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-04-02 13:29:37.284562: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "cannot import name 'LangtestRetrieverEvaluator' from 'langtest.evaluation' (/usr/local/lib/python3.10/dist-packages/langtest/evaluation/__init__.py) please install llama_index using `pip install llama-index`\n",
            "./.langtest\n",
            "\n",
            "\n",
            "================================================================================\n",
            "                                   robustness                                   \n",
            "================================================================================\n",
            "INFO:langtest.leaderboard:robustness Leaderboard\n",
            "|    | model               |   avg |     std |   MMLU |   MedMCQA |   MedQA |   PubMedQA |\n",
            "|---:|:--------------------|------:|--------:|-------:|----------:|--------:|-----------:|\n",
            "|  1 | google/flan-t5-base | 98.25 | 2.06155 |     97 |        96 |     100 |        100 |\n",
            "--------------------------------------------------------------------------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!langtest show-leaderboard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To benchmark a different model, simply replace `google/flan-t5-base` with your desired model identifier in the `!langtest eval` command. For the hub keep -h huggingface unless your model resides elsewhere."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lat4hO76ATVr",
        "outputId": "c056cc6a-0584-4ddb-ae68-0086faa0a6eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-04-02 13:34:00.338874: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-02 13:34:00.338947: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-02 13:34:00.347016: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-04-02 13:34:01.464894: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "cannot import name 'LangtestRetrieverEvaluator' from 'langtest.evaluation' (/usr/local/lib/python3.10/dist-packages/langtest/evaluation/__init__.py) please install llama_index using `pip install llama-index`\n",
            "INFO:langtest.leaderboard:Initializing new langtest leaderboard...\n",
            "/root/.langtest/\n",
            "INFO:langtest.leaderboard:Testcases already exist at: /root/.langtest/testcases/question-answering&MedMCQA,PubMedQA,MMLU,MedQA&robustness\n",
            "tokenizer_config.json: 100% 2.54k/2.54k [00:00<00:00, 11.7MB/s]\n",
            "spiece.model: 100% 792k/792k [00:00<00:00, 94.5MB/s]\n",
            "tokenizer.json: 100% 2.42M/2.42M [00:00<00:00, 3.33MB/s]\n",
            "special_tokens_map.json: 100% 2.20k/2.20k [00:00<00:00, 11.6MB/s]\n",
            "config.json: 100% 662/662 [00:00<00:00, 3.84MB/s]\n",
            "model.safetensors: 100% 3.13G/3.13G [00:11<00:00, 268MB/s]\n",
            "generation_config.json: 100% 147/147 [00:00<00:00, 795kB/s]\n",
            "Test Configuration : \n",
            " {\n",
            " \"model_parameters\": {\n",
            "  \"device\": 0,\n",
            "  \"max_tokens\": 64,\n",
            "  \"task\": \"text2text-generation\"\n",
            " },\n",
            " \"tests\": {\n",
            "  \"defaults\": {\n",
            "   \"min_pass_rate\": 0.65\n",
            "  },\n",
            "  \"robustness\": {\n",
            "   \"add_typo\": {\n",
            "    \"min_pass_rate\": 0.7\n",
            "   }\n",
            "  }\n",
            " }\n",
            "}\n",
            "================================================================================\n",
            "                                    MedMCQA                                     \n",
            "================================================================================\n",
            "Generating testcases...: 100% 1/1 [00:00<00:00, 14122.24it/s]\n",
            "WARNING:root:[W009] Removing samples where no transformation has been applied:\n",
            "[W010] - Test 'add_typo': 134 samples removed out of 4183\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "================================================================================\n",
            "                                    PubMedQA                                    \n",
            "================================================================================\n",
            "Generating testcases...: 100% 1/1 [00:00<00:00, 19972.88it/s]\n",
            "WARNING:root:[W009] Removing samples where no transformation has been applied:\n",
            "[W010] - Test 'add_typo': 3 samples removed out of 1000\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "================================================================================\n",
            "                                      MMLU                                      \n",
            "================================================================================\n",
            "Generating testcases...: 100% 1/1 [00:00<00:00, 18001.30it/s]\n",
            "WARNING:root:[W009] Removing samples where no transformation has been applied:\n",
            "[W010] - Test 'add_typo': 42 samples removed out of 1089\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "================================================================================\n",
            "                                     MedQA                                      \n",
            "================================================================================\n",
            "Generating testcases...: 100% 1/1 [00:00<00:00, 21076.90it/s]\n",
            "WARNING:root:[W009] Removing samples where no transformation has been applied:\n",
            "[W010] - Test 'add_typo': 58 samples removed out of 1323\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "INFO:langtest.leaderboard:Loading testcases from /root/.langtest/testcases/question-answering&MedMCQA,PubMedQA,MMLU,MedQA&robustness.\n",
            "================================================================================\n",
            "                                    MedMCQA                                     \n",
            "================================================================================\n",
            "Running testcases... :   0% 5/4049 [00:01<16:58,  3.97it/s]/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1157: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "Running testcases... : 100% 4049/4049 [13:05<00:00,  5.16it/s]\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "================================================================================\n",
            "                                    PubMedQA                                    \n",
            "================================================================================\n",
            "Running testcases... : 100% 997/997 [04:16<00:00,  3.89it/s]\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "================================================================================\n",
            "                                      MMLU                                      \n",
            "================================================================================\n",
            "Running testcases... : 100% 1047/1047 [03:27<00:00,  5.05it/s]\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "================================================================================\n",
            "                                     MedQA                                      \n",
            "================================================================================\n",
            "Running testcases... : 100% 1265/1265 [04:08<00:00,  5.09it/s]\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "INFO:langtest.leaderboard:Updating leaderboard...\n",
            "\n",
            "\n",
            "================================================================================\n",
            "                                   robustness                                   \n",
            "================================================================================\n",
            "INFO:langtest.leaderboard:robustness Leaderboard\n",
            "|    | model                |   avg |     std |   MMLU |   MedMCQA |   MedQA |   PubMedQA |\n",
            "|---:|:---------------------|------:|--------:|-------:|----------:|--------:|-----------:|\n",
            "|  1 | google/flan-t5-base  | 98.25 | 2.06155 |     97 |        96 |     100 |        100 |\n",
            "|  2 | google/flan-t5-large | 91.25 | 4.272   |     90 |        86 |      96 |         93 |\n",
            "--------------------------------------------------------------------------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!langtest eval -m google/flan-t5-large -h huggingface -c config.yml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o8tlvlj7IIm3",
        "outputId": "5a667aca-3ef9-418d-abf9-4e877874214f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-04-02 14:05:07.671633: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-02 14:05:07.671708: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-02 14:05:07.679796: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-04-02 14:05:08.800860: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "cannot import name 'LangtestRetrieverEvaluator' from 'langtest.evaluation' (/usr/local/lib/python3.10/dist-packages/langtest/evaluation/__init__.py) please install llama_index using `pip install llama-index`\n",
            "./.langtest\n",
            "\n",
            "\n",
            "================================================================================\n",
            "                                   robustness                                   \n",
            "================================================================================\n",
            "INFO:langtest.leaderboard:robustness Leaderboard\n",
            "|    | model                |   avg |     std |   MMLU |   MedMCQA |   MedQA |   PubMedQA |\n",
            "|---:|:---------------------|------:|--------:|-------:|----------:|--------:|-----------:|\n",
            "|  1 | google/flan-t5-base  | 98.25 | 2.06155 |     97 |        96 |     100 |        100 |\n",
            "|  2 | google/flan-t5-large | 91.25 | 4.272   |     90 |        86 |      96 |         93 |\n",
            "--------------------------------------------------------------------------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!langtest show-leaderboard"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
