{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![logog](https://raw.githubusercontent.com/Pacific-AI-Corp/langtest/main/docs/assets/images/logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Pacific-AI-Corp/langtest/blob/main/demo/tutorials/llm_notebooks/NER%20Casual%20LLM.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LangTest** is an open-source python library designed to help developers deliver safe and effective Natural Language Processing (NLP) models. Whether you are using **John Snow Labs, Hugging Face, Spacy** models or **OpenAI, Cohere, AI21, Hugging Face Inference API and Azure-OpenAI** based LLMs, it has got you covered. You can test any Named Entity Recognition (NER), Text Classification, fill-mask, Translation model using the library. We also support testing LLMS for Question-Answering, Summarization and text-generation tasks on benchmark datasets. The library supports 60+ out of the box tests. For a complete list of supported test categories, please refer to the [documentation](http://langtest.org/docs/pages/docs/test_categories).\n",
    "\n",
    "Metrics are calculated by comparing the model's extractions in the original list of sentences against the extractions carried out in the noisy list of sentences. The original annotated labels are not used at any point, we are simply comparing the model against itself in a 2 settings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started with LangTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install \"langtest[evaluate,openai]==2.2.0\" requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Harness and Its Parameters\n",
    "\n",
    "The Harness class is a testing class for Natural Language Processing (NLP) models. It evaluates the performance of a NLP model on a given task using test data and generates a report with test results.Harness can be imported from the LangTest library in the following way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Harness from the LangTest library\n",
    "from langtest import Harness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It imports the Harness class from within the module, that is designed to provide a blueprint or framework for conducting NLP testing, and that instances of the Harness class can be customized or configured for different testing scenarios or environments.\n",
    "\n",
    "Here is a list of the different parameters that can be passed to the Harness function:\n",
    "\n",
    "<br/>\n",
    "\n",
    "\n",
    "| Parameter  | Description |  \n",
    "| - | - | \n",
    "|**task**     |Task for which the model is to be evaluated (ner)|\n",
    "| **model**     | Specifies the model(s) to be evaluated. This parameter can be provided as either a dictionary or a list of dictionaries. Each dictionary should contain the following keys: <ul><li>model (mandatory): \tPipelineModel or path to a saved model or pretrained pipeline/model from hub.</li><li>hub (mandatory): Hub (library) to use in back-end for loading model from public models hub or from path</li></ul>|\n",
    "| **data**      | The data to be used for evaluation. A dictionary providing flexibility and options for data sources. It should include the following keys: <ul><li>data_source (mandatory): The source of the data.</li><li>subset (optional): The subset of the data.</li><li>feature_column (optional): The column containing the features.</li><li>target_column (optional): The column containing the target labels.</li><li>split (optional): The data split to be used.</li><li>source (optional): Set to 'huggingface' when loading Hugging Face dataset.</li></ul> |\n",
    "| **config**    | Configuration for the tests to be performed, specified in the form of a YAML file. |\n",
    "\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A system prompt, in the context of Language Model (LLM), is a predefined input that guides the model to generate a specific structured output. This is particularly useful in tasks where the output needs to follow a certain format or structure.\n",
    "\n",
    "For instance, in Named Entity Recognition (NER), a task in Natural Language Processing (NLP), we might want the model to identify and classify named entities in a text into predefined categories like person names, organizations, locations, medical codes, time expressions, quantities, monetary values, percentages, etc.\n",
    "\n",
    "In such a case, a system prompt could be a sentence with placeholders for the model to fill. The LLM model, upon receiving this prompt, generates an output that fills these placeholders with appropriate entities, thereby producing a structured output.\n",
    "\n",
    "This approach of using system prompts helps in controlling the output of the LLM models, making them more useful in practical applications where structured outputs are required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI Model Testing For NER\n",
    "\n",
    "In this section, we dive into testing of OpenAI models in NER task.\n",
    "\n",
    "LangTest supports robustness and accuracy tests for LLM testing for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set environment for OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"<YOUR_API_KEY>\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CoNLL\n",
    "!wget https://github.com/JohnSnowLabs/langtest/raw/main/langtest/data/conll/sample.conll"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup and Configure Harness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Configuration : \n",
      " {\n",
      " \"model_parameters\": {\n",
      "  \"temperature\": 0\n",
      " },\n",
      " \"tests\": {\n",
      "  \"defaults\": {\n",
      "   \"min_pass_rate\": 1.0\n",
      "  },\n",
      "  \"robustness\": {\n",
      "   \"lowercase\": {\n",
      "    \"min_pass_rate\": 0.7\n",
      "   }\n",
      "  },\n",
      "  \"accuracy\": {\n",
      "   \"min_f1_score\": {\n",
      "    \"min_score\": 0.7\n",
      "   }\n",
      "  }\n",
      " }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Create a Harness object\n",
    "h = Harness(task=\"ner\",\n",
    "            model={\n",
    "                \"model\": \"gpt-3.5-turbo-instruct\",\n",
    "                \"hub\": \"openai\",},\n",
    "            data={\n",
    "                \"data_source\": '../../data/conll03.conll'\n",
    "            },\n",
    "            config={\n",
    "                \"model_parameters\": {\n",
    "                    \"temperature\": 0,\n",
    "                },\n",
    "                \"tests\": {\n",
    "                    \"defaults\": {\n",
    "                        \"min_pass_rate\": 1.0\n",
    "                    },\n",
    "                    \"robustness\": {\n",
    "                        \"lowercase\": {\n",
    "                            \"min_pass_rate\": 0.7\n",
    "                        }\n",
    "                    },\n",
    "                    \"accuracy\": {\n",
    "                        \"min_f1_score\": {\n",
    "                            \"min_score\": 0.7,\n",
    "                        },\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "            )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have specified task as NER, hub as OpenAI and model as GPT-3.5.\n",
    "\n",
    "For dataset we used default `Conll` dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For tests we used lowercase and uppercase. Other available robustness tests for QA task are:\n",
    "* `add_context`\n",
    "* `add_contraction`\n",
    "* `add_punctuation`\n",
    "* `add_typo`\n",
    "* `add_ocr_typo`\n",
    "* `american_to_british`\n",
    "* `british_to_american`\n",
    "* `lowercase`\n",
    "* `strip_punctuation`\n",
    "* `titlecase`\n",
    "* `uppercase`\n",
    "* `number_to_word`\n",
    "* `add_abbreviation`\n",
    "* `add_speech_to_text_typo`\n",
    "* `add_slangs`\n",
    "* `dyslexia_word_swap`\n",
    "* `multiple_perturbations`\n",
    "* `adjective_synonym_swap`\n",
    "* `adjective_antonym_swap`\n",
    "* `strip_all_punctuation`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Available Bias tests for QA task are:\n",
    "\n",
    "* `replace_to_male_pronouns`\n",
    "* `replace_to_female_pronouns`\n",
    "* `replace_to_neutral_pronouns`\n",
    "* `replace_to_high_income_country`\n",
    "* `replace_to_low_income_country`\n",
    "* `replace_to_upper_middle_income_country`\n",
    "* `replace_to_lower_middle_income_country`\n",
    "* `replace_to_white_firstnames`\n",
    "* `replace_to_black_firstnames`\n",
    "* `replace_to_hispanic_firstnames`\n",
    "* `replace_to_asian_firstnames`\n",
    "* `replace_to_white_lastnames`\n",
    "* `replace_to_sikh_names`\n",
    "* `replace_to_christian_names`\n",
    "* `replace_to_hindu_names`\n",
    "* `replace_to_muslim_names`\n",
    "* `replace_to_inter_racial_lastnames`\n",
    "* `replace_to_native_american_lastnames`\n",
    "* `replace_to_asian_lastnames`\n",
    "* `replace_to_hispanic_lastnames`\n",
    "* `replace_to_black_lastnames`\n",
    "* `replace_to_parsi_names`\n",
    "* `replace_to_jain_names`\n",
    "* `replace_to_buddhist_names`\n",
    "\n",
    "Available Representation tests for QA task are:\n",
    "\n",
    "* `min_gender_representation_count`\n",
    "* `min_ethnicity_name_representation_count`\n",
    "* `min_religion_name_representation_count`\n",
    "* `min_country_economic_representation_count`\n",
    "* `min_gender_representation_proportion`\n",
    "* `min_ethnicity_name_representation_proportion`\n",
    "* `min_religion_name_representation_proportion`\n",
    "* `min_country_economic_representation_proportion`\n",
    "\n",
    "\n",
    "Available Accuracy tests for QA task are:\n",
    "\n",
    "* `min_exact_match_score`\n",
    "* `min_bleu_score`\n",
    "* `min_rouge1_score`\n",
    "* `min_rouge2_score`\n",
    "* `min_rougeL_score`\n",
    "* `min_rougeLsum_score`\n",
    "\n",
    "\n",
    "Available Fairness tests for QA task are:\n",
    "\n",
    "* `max_gender_rouge1_score`\n",
    "* `max_gender_rouge2_score`\n",
    "* `max_gender_rougeL_score`\n",
    "* `max_gender_rougeLsum_score`\n",
    "* `min_gender_rouge1_score`\n",
    "* `min_gender_rouge2_score`\n",
    "* `min_gender_rougeL_score`\n",
    "* `min_gender_rougeLsum_score`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also set prompts and other model parameters in config. Possible parameters are:\n",
    "* `user_prompt:` Promt to be given to the model.\n",
    "* `temperature:` Temperature of the model.\n",
    "* `max_tokens:` Maximum number of output tokens allowed for model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_parameters': {'temperature': 0},\n",
       " 'tests': {'defaults': {'min_pass_rate': 1.0},\n",
       "  'robustness': {'lowercase': {'min_pass_rate': 0.7}},\n",
       "  'accuracy': {'min_f1_score': {'min_score': 0.7}}}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.configure({\n",
    "    \"model_parameters\": {\n",
    "        \"temperature\": 0,\n",
    "    },\n",
    "    \"tests\": {\n",
    "        \"defaults\": {\n",
    "            \"min_pass_rate\": 1.0\n",
    "        },\n",
    "        \"robustness\": {\n",
    "            \"lowercase\": {\n",
    "                \"min_pass_rate\": 0.7\n",
    "            }\n",
    "        },\n",
    "        \"accuracy\": {\n",
    "            \"min_f1_score\": {\n",
    "                \"min_score\": 0.7,\n",
    "            },\n",
    "        }\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have configured the harness to perform two robustness tests (uppercase and lowercase) and defined the minimum pass rate for each test.\n",
    "\n",
    "➤ You can adjust the level of transformation in the sentence by using the \"`prob`\" parameter, which controls the proportion of words to be changed during robustness tests.\n",
    "\n",
    "➤ **NOTE** : \"`prob`\" defaults to 1.0, which means all words will be transformed.\n",
    "```\n",
    "harness.configure(\n",
    "{\n",
    " 'tests': {\n",
    "    'defaults': {'min_pass_rate': 0.65},\n",
    "      'robustness': {\n",
    "        'lowercase': {'min_pass_rate': 0.66, 'prob': 0.50}, \n",
    "        'uppercase':{'min_pass_rate': 0.60, 'prob': 0.70},\n",
    "      }\n",
    "  }\n",
    "})\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as rnd \n",
    "\n",
    "rnd.seed(0)\n",
    "\n",
    "h.data = rnd.choices(h.data, k=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating the test cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating testcases...: 100%|██████████| 2/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.generate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "harness.generate() method automatically generates the test cases (based on the provided configuration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>test_type</th>\n",
       "      <th>original</th>\n",
       "      <th>test_case</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>robustness</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>He won acclaim for the insights that he gave i...</td>\n",
       "      <td>he won acclaim for the insights that he gave i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>robustness</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>FLORIDA AT CINCINNATI</td>\n",
       "      <td>florida at cincinnati</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>robustness</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>ISSUER : Bay Co Building Authority ST : MI</td>\n",
       "      <td>issuer : bay co building authority st : mi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>robustness</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>Chernomyrdin said on Thursday after a meeting ...</td>\n",
       "      <td>chernomyrdin said on thursday after a meeting ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>robustness</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>Wigan 42 Bradford Bulls 36</td>\n",
       "      <td>wigan 42 bradford bulls 36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>min_f1_score</td>\n",
       "      <td>-</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>min_f1_score</td>\n",
       "      <td>-</td>\n",
       "      <td>MISC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>min_f1_score</td>\n",
       "      <td>-</td>\n",
       "      <td>PER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>min_f1_score</td>\n",
       "      <td>-</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>min_f1_score</td>\n",
       "      <td>-</td>\n",
       "      <td>LOC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>105 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       category     test_type  \\\n",
       "0    robustness     lowercase   \n",
       "1    robustness     lowercase   \n",
       "2    robustness     lowercase   \n",
       "3    robustness     lowercase   \n",
       "4    robustness     lowercase   \n",
       "..          ...           ...   \n",
       "100    accuracy  min_f1_score   \n",
       "101    accuracy  min_f1_score   \n",
       "102    accuracy  min_f1_score   \n",
       "103    accuracy  min_f1_score   \n",
       "104    accuracy  min_f1_score   \n",
       "\n",
       "                                              original  \\\n",
       "0    He won acclaim for the insights that he gave i...   \n",
       "1                                FLORIDA AT CINCINNATI   \n",
       "2           ISSUER : Bay Co Building Authority ST : MI   \n",
       "3    Chernomyrdin said on Thursday after a meeting ...   \n",
       "4                           Wigan 42 Bradford Bulls 36   \n",
       "..                                                 ...   \n",
       "100                                                  -   \n",
       "101                                                  -   \n",
       "102                                                  -   \n",
       "103                                                  -   \n",
       "104                                                  -   \n",
       "\n",
       "                                             test_case  \n",
       "0    he won acclaim for the insights that he gave i...  \n",
       "1                                florida at cincinnati  \n",
       "2           issuer : bay co building authority st : mi  \n",
       "3    chernomyrdin said on thursday after a meeting ...  \n",
       "4                           wigan 42 bradford bulls 36  \n",
       "..                                                 ...  \n",
       "100                                                ORG  \n",
       "101                                               MISC  \n",
       "102                                                PER  \n",
       "103                                                  O  \n",
       "104                                                LOC  \n",
       "\n",
       "[105 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.testcases()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "harness.testcases() method displays the produced test cases in form of a pandas data frame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running testcases... :  99%|█████████▉| 104/105 [06:20<00:03,  3.66s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Called after harness.generate() and is to used to run all the tests.  Returns a pass/fail flag for each test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = h.generated_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method returns the generated results in the form of a pandas dataframe, which provides a convenient and easy-to-use format for working with the test results. You can use this method to quickly identify the test cases that failed and to determine where fixes are needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>test_type</th>\n",
       "      <th>original</th>\n",
       "      <th>test_case</th>\n",
       "      <th>expected_result</th>\n",
       "      <th>actual_result</th>\n",
       "      <th>pass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>robustness</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>He won acclaim for the insights that he gave i...</td>\n",
       "      <td>he won acclaim for the insights that he gave i...</td>\n",
       "      <td>Europe: Location, Europe: Location, 20th: Date...</td>\n",
       "      <td>he: PERSON, modern: DATE, europe: LOCATION, eu...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>robustness</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>FLORIDA AT CINCINNATI</td>\n",
       "      <td>florida at cincinnati</td>\n",
       "      <td>FLORIDA: LOCATION, CINCINNATI: LOCATION</td>\n",
       "      <td>florida: LOCATION, cincinnati: LOCATION</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>robustness</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>ISSUER : Bay Co Building Authority ST : MI</td>\n",
       "      <td>issuer : bay co building authority st : mi</td>\n",
       "      <td>Bay Co Building Authority: Organization, ST: L...</td>\n",
       "      <td>bay: issuer, co: issuer, building: issuer, aut...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>robustness</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>Chernomyrdin said on Thursday after a meeting ...</td>\n",
       "      <td>chernomyrdin said on thursday after a meeting ...</td>\n",
       "      <td>Chernomyrdin: Person, Thursday: Date, Lebed: P...</td>\n",
       "      <td>chernomyrdin: PERSON, thursday: DATE, lebed: P...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>robustness</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>Wigan 42 Bradford Bulls 36</td>\n",
       "      <td>wigan 42 bradford bulls 36</td>\n",
       "      <td>Wigan: Location, 42: Number, Bradford Bulls: O...</td>\n",
       "      <td>wigan: ORG, 42: CARDINAL, bradford: ORG, bulls...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>robustness</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>Indonesian President Suharto has asked busines...</td>\n",
       "      <td>indonesian president suharto has asked busines...</td>\n",
       "      <td>Indonesian: Location, President: Title, Suhart...</td>\n",
       "      <td>indonesian: GPE, president: TITLE, suharto: PE...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>min_f1_score</td>\n",
       "      <td>-</td>\n",
       "      <td>ORG</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>min_f1_score</td>\n",
       "      <td>-</td>\n",
       "      <td>PER</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>min_f1_score</td>\n",
       "      <td>-</td>\n",
       "      <td>O</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>min_f1_score</td>\n",
       "      <td>-</td>\n",
       "      <td>LOC</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>104 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       category     test_type  \\\n",
       "0    robustness     lowercase   \n",
       "1    robustness     lowercase   \n",
       "2    robustness     lowercase   \n",
       "3    robustness     lowercase   \n",
       "4    robustness     lowercase   \n",
       "..          ...           ...   \n",
       "99   robustness     lowercase   \n",
       "100    accuracy  min_f1_score   \n",
       "101    accuracy  min_f1_score   \n",
       "102    accuracy  min_f1_score   \n",
       "103    accuracy  min_f1_score   \n",
       "\n",
       "                                              original  \\\n",
       "0    He won acclaim for the insights that he gave i...   \n",
       "1                                FLORIDA AT CINCINNATI   \n",
       "2           ISSUER : Bay Co Building Authority ST : MI   \n",
       "3    Chernomyrdin said on Thursday after a meeting ...   \n",
       "4                           Wigan 42 Bradford Bulls 36   \n",
       "..                                                 ...   \n",
       "99   Indonesian President Suharto has asked busines...   \n",
       "100                                                  -   \n",
       "101                                                  -   \n",
       "102                                                  -   \n",
       "103                                                  -   \n",
       "\n",
       "                                             test_case  \\\n",
       "0    he won acclaim for the insights that he gave i...   \n",
       "1                                florida at cincinnati   \n",
       "2           issuer : bay co building authority st : mi   \n",
       "3    chernomyrdin said on thursday after a meeting ...   \n",
       "4                           wigan 42 bradford bulls 36   \n",
       "..                                                 ...   \n",
       "99   indonesian president suharto has asked busines...   \n",
       "100                                                ORG   \n",
       "101                                                PER   \n",
       "102                                                  O   \n",
       "103                                                LOC   \n",
       "\n",
       "                                       expected_result  \\\n",
       "0    Europe: Location, Europe: Location, 20th: Date...   \n",
       "1              FLORIDA: LOCATION, CINCINNATI: LOCATION   \n",
       "2    Bay Co Building Authority: Organization, ST: L...   \n",
       "3    Chernomyrdin: Person, Thursday: Date, Lebed: P...   \n",
       "4    Wigan: Location, 42: Number, Bradford Bulls: O...   \n",
       "..                                                 ...   \n",
       "99   Indonesian: Location, President: Title, Suhart...   \n",
       "100                                                0.7   \n",
       "101                                                  -   \n",
       "102                                                0.7   \n",
       "103                                                0.7   \n",
       "\n",
       "                                         actual_result   pass  \n",
       "0    he: PERSON, modern: DATE, europe: LOCATION, eu...  False  \n",
       "1              florida: LOCATION, cincinnati: LOCATION   True  \n",
       "2    bay: issuer, co: issuer, building: issuer, aut...  False  \n",
       "3    chernomyrdin: PERSON, thursday: DATE, lebed: P...  False  \n",
       "4    wigan: ORG, 42: CARDINAL, bradford: ORG, bulls...  False  \n",
       "..                                                 ...    ...  \n",
       "99   indonesian: GPE, president: TITLE, suharto: PE...  False  \n",
       "100                                                0.0  False  \n",
       "101                                                  -      -  \n",
       "102                                                0.4  False  \n",
       "103                                                0.0  False  \n",
       "\n",
       "[104 rows x 7 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can call `.report()` which summarizes the results giving information about pass and fail counts and overall test pass/fail flag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>test_type</th>\n",
       "      <th>fail_count</th>\n",
       "      <th>pass_count</th>\n",
       "      <th>pass_rate</th>\n",
       "      <th>minimum_pass_rate</th>\n",
       "      <th>pass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>robustness</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>69</td>\n",
       "      <td>31</td>\n",
       "      <td>31%</td>\n",
       "      <td>70%</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>min_f1_score</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0%</td>\n",
       "      <td>100%</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     category     test_type  fail_count  pass_count pass_rate  \\\n",
       "0  robustness     lowercase          69          31       31%   \n",
       "1    accuracy  min_f1_score           4           0        0%   \n",
       "\n",
       "  minimum_pass_rate   pass  \n",
       "0               70%  False  \n",
       "1              100%  False  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
